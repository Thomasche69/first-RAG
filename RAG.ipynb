{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('ArtOfWar.pdf')\n",
    "\n",
    "# Load the document\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "chunk_size = 350\n",
    "chunk_overlap = 75\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators = [\"\\n\\n\", \"Chapter\",\".\"],\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n",
    "# Merge all text from documents into a single string\n",
    "merged_text = \" \".join(doc.page_content for doc in data)\n",
    "\n",
    "# Now split the combined text\n",
    "docs = splitter.split_text(merged_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aalen\\OneDrive\\桌面\\deep learning\\RAG_first\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalen\\AppData\\Local\\Temp\\ipykernel_11792\\4067356748.py:26: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding=HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB initialized successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define persist directory\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Remove and reinitialize ChromaDB storage to avoid corruption\n",
    "if os.path.exists(persist_directory):\n",
    "    shutil.rmtree(persist_directory)\n",
    "os.makedirs(persist_directory, exist_ok=True)\n",
    "\n",
    "# Ensure docs is a list of Document objects\n",
    "if isinstance(docs[0], str):\n",
    "    docs = [Document(page_content=text) for text in docs]  # Convert strings to Document objects\n",
    "\n",
    "# Check for valid documents\n",
    "if not docs or not isinstance(docs[0], Document):\n",
    "    raise ValueError(\"docs must be a non-empty list of Document objects.\")\n",
    "\n",
    "# Initialize Chroma vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    persist_directory=persist_directory  # Ensure a dedicated, writable directory\n",
    ")\n",
    "\n",
    "print(\"ChromaDB initialized successfully! ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "20. Hold out baits to entice the enemy. Feign disorder, and crush him.\n",
      "[All commentators, except Chang Y u, say, \"When he is in disorder, crush\n",
      "him.\" It is more natural to suppose that Sun Tzu is still illustrating the uses\n",
      "of deception in war.]\n",
      "21. If he is secure at all points, be prepared for him. If he is in superior\n",
      "strength, evade him.\n",
      "22\n",
      "\n",
      "\n",
      ". 72 Can we then recklessly arraign Sun Tzu for dis-\n",
      "regarding truth and honesty?\n",
      "66 See XIII. ss. 11, note.\n",
      "67 This is a rather obscure allusion to the TSO CHUAN, where Tzu-ch‘an says: \"If you have a piece of\n",
      "beautiful brocade, you will not employ a mere learner to make it up.\"\n",
      "68 Cf. TAO TE CHING, ch. 31\n",
      "\n",
      "\n",
      ". The style of this fragment is not noticeable different from that of\n",
      "Sun Tzu himself, but no commentator raises a doubt as to its genuineness.]\n",
      "23. The Book of Army Management says:\n",
      "[It is perhaps signiﬁcant that none of the earlier commentators give us any\n",
      "information about this work\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalen\\AppData\\Local\\Temp\\ipykernel_11792\\2959439415.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  top_query = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "query = \"What does Sun Tzu say about deception?\"\t\n",
    "top_query = retriever.get_relevant_documents(query)\n",
    "for queries in top_query[:3]:\n",
    "    print(queries.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Define the LLM\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    endpoint_url=MODEL_NAME,  # Replace with your HF API URL\n",
    "    huggingfacehub_api_token=\"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\",  # Load API Key from env\n",
    "    temperature=0.7,  # Adjust response creativity\n",
    "    max_new_tokens=512,  # Adjust response length\n",
    "\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = PromptTemplate(\n",
    "    template=\"\"\"Use the retrieved context to provide a well-researched and thorough response.\n",
    "If the answer is unknown, say you don't know—do not make up an answer.\n",
    "\n",
    "Your response should:\n",
    "- Explain Sun Tzu’s views on deception in detail.\n",
    "- Provide at least one historical example of deception in war.\n",
    "- Include a direct quote from *The Art of War* if available.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Detailed Answer:\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "# Create RetrievalQA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
